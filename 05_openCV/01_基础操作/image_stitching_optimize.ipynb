{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pyimagesearch.com/wp-content/uploads/2018/12/image_stitching_opencv_ideal-1024x458.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Weâ€™ll be reviewing basic image processing operations including threshold, contour extraction, morphological operations, etc. in order to obtain our desired result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load our input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[TNFO] load images finished\n"
     ]
    }
   ],
   "source": [
    "# grab the paths to the input images and initialize our images list\n",
    "img_path = \"./scottsdale\"\n",
    "print(\"[INFO] loading images...\") \n",
    "imagepath = sorted(list(paths.list_images(img_path))) # grab our imagePaths from img_path to format a list\n",
    "\n",
    "# initialize our images list\n",
    "images = []\n",
    "# loop over the image paths, load each one, and add them to our images to stich list\n",
    "for imagepath in imagepath:\n",
    "    image = cv2.imread(imagepath)\n",
    "    images.append(image)\n",
    "# print(images)\n",
    "print(\"[TNFO] load images finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize OpenCV's image sticher object and then perform the image stitching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TNFO] stitching images ...\n"
     ]
    }
   ],
   "source": [
    "print(\"[TNFO] stitching images ...\")\n",
    "\n",
    "stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()\n",
    "(status, stitched) = stitcher.stitch(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, name):\n",
    "    cv2.imshow(\"%s\" %(name), img)\n",
    "    key = cv2.waitKey()\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] cropping...\n"
     ]
    }
   ],
   "source": [
    "crop = 1\n",
    "\n",
    "# if the status is '0', then OpenCV successfully performed image stitching\n",
    "if status == 0:\n",
    "    # check to see if we supposed to crop out the largest rectangular region from the stitched image\n",
    "    if crop > 0:\n",
    "        # create a 10 pixel border surrounding the stitched image\n",
    "        print(\"[INFO] cropping...\")\n",
    "        stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10,cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "        \n",
    "        # convert the stitched image to grayscale and threshold it\n",
    "        # such that all pixels greater than zero are set to 255\n",
    "        # (foreground) while all others remain 0 (background)\n",
    "        gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        # find all external contours in the threshold image then find\n",
    "        # the *largest* contour which will be the contour/outline of\n",
    "        # the stitched image\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        \n",
    "        # allocate memory for the mask which will contain the\n",
    "        # rectangular bounding box of the stitched image region\n",
    "        mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(mask, (x, y), (x + w, y + h), 255, -1)\n",
    "        \n",
    "        # create two copies of the mask: one to serve as our actual\n",
    "        # minimum rectangular region and another to serve as a counter\n",
    "        # for how many pixels need to be removed to form the minimum\n",
    "        # rectangular region\n",
    "        minRect = mask.copy()\n",
    "        sub = mask.copy()\n",
    "\n",
    "        # keep looping until there are no non-zero pixels left in the\n",
    "        # subtracted image\n",
    "        while cv2.countNonZero(sub) > 0:\n",
    "            # erode the minimum rectangular mask and then subtract\n",
    "            # the thresholded image from the minimum rectangular mask\n",
    "            # so we can count if there are any non-zero pixels left\n",
    "            minRect = cv2.erode(minRect, None)\n",
    "            sub = cv2.subtract(minRect, thresh)\n",
    "\n",
    "        # find contours in the minimum rectangular mask and then\n",
    "        # extract the bounding box (x, y)-coordinates\n",
    "        cnts = cv2.findContours(minRect.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "        # use the bounding box coordinates to extract the our final stitched image\n",
    "        stitched = stitched[y:y + h, x:x + w]\n",
    "\n",
    "    # write the output stitched image to disk\n",
    "    cv2.imwrite(\"./scottsdale/out_optim.png\", stitched)\n",
    "\n",
    "    # display the output stitched image to our screen\n",
    "    show(stitched, name=\"./scottsdale/out_optim.png\")\n",
    "\n",
    "# otherwise the stitching failed, likely due to not enough keypoints)\n",
    "# being detected\n",
    "else:\n",
    "    print(\"[ERROR] image stitching failed ({})\".format(status))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
